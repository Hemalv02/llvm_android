From 73a0a6b42d5403506242196be4fbb9fdb9a92778 Mon Sep 17 00:00:00 2001
From: Stephen Hines <srhines@google.com>
Date: Wed, 4 Nov 2020 16:22:36 -0800
Subject: [PATCH] Revert several changes that break cfi_test.basic

Bug: http://b/171505867

6b5b6511a5 "[InstCombine] add/move tests for ptr diff; NFC"
8b30067919 "[InstCombine] improve fold of pointer differences"
3ca8b9a560 "[InstCombine] give a name to an intermediate value for easier tracking; NFC"
3a3c9519e2 "[InstCombine] Negator: 0 - (X + Y)  -->  (-X) - Y  iff a single operand negated"
70207816e3 "[InstCombine] add ptr difference tests; NFC"
f5df5cd558 "Recommit "[InstCombine] Negator: -(X << C)  -->  X * (-1 << C)""
---
 .../InstCombine/InstCombineAddSub.cpp         |  36 ++-
 .../InstCombine/InstCombineNegator.cpp        |  43 +--
 .../CodeGen/AMDGPU/reqd-work-group-size.ll    |  17 +-
 llvm/test/Transforms/InstCombine/icmp.ll      |   3 +-
 llvm/test/Transforms/InstCombine/sub-gep.ll   | 250 +-----------------
 .../InstCombine/sub-of-negatible.ll           |  10 +-
 llvm/test/Transforms/InstCombine/sub.ll       | 187 ++++++++++++-
 7 files changed, 230 insertions(+), 316 deletions(-)

diff --git a/llvm/lib/Transforms/InstCombine/InstCombineAddSub.cpp b/llvm/lib/Transforms/InstCombine/InstCombineAddSub.cpp
index 7fc472de579..68b3f5309b1 100644
--- a/llvm/lib/Transforms/InstCombine/InstCombineAddSub.cpp
+++ b/llvm/lib/Transforms/InstCombine/InstCombineAddSub.cpp
@@ -1636,27 +1636,43 @@ Value *InstCombinerImpl::OptimizePointerDifference(Value *LHS, Value *RHS,
   // this.
   bool Swapped = false;
   GEPOperator *GEP1 = nullptr, *GEP2 = nullptr;
-  if (!isa<GEPOperator>(LHS) && isa<GEPOperator>(RHS)) {
-    std::swap(LHS, RHS);
-    Swapped = true;
-  }
 
-  // Require at least one GEP with a common base pointer on both sides.
-  if (auto *LHSGEP = dyn_cast<GEPOperator>(LHS)) {
+  // For now we require one side to be the base pointer "A" or a constant
+  // GEP derived from it.
+  if (GEPOperator *LHSGEP = dyn_cast<GEPOperator>(LHS)) {
     // (gep X, ...) - X
     if (LHSGEP->getOperand(0) == RHS) {
       GEP1 = LHSGEP;
-    } else if (auto *RHSGEP = dyn_cast<GEPOperator>(RHS)) {
+      Swapped = false;
+    } else if (GEPOperator *RHSGEP = dyn_cast<GEPOperator>(RHS)) {
       // (gep X, ...) - (gep X, ...)
       if (LHSGEP->getOperand(0)->stripPointerCasts() ==
-          RHSGEP->getOperand(0)->stripPointerCasts()) {
-        GEP1 = LHSGEP;
+            RHSGEP->getOperand(0)->stripPointerCasts()) {
         GEP2 = RHSGEP;
+        GEP1 = LHSGEP;
+        Swapped = false;
+      }
+    }
+  }
+
+  if (GEPOperator *RHSGEP = dyn_cast<GEPOperator>(RHS)) {
+    // X - (gep X, ...)
+    if (RHSGEP->getOperand(0) == LHS) {
+      GEP1 = RHSGEP;
+      Swapped = true;
+    } else if (GEPOperator *LHSGEP = dyn_cast<GEPOperator>(LHS)) {
+      // (gep X, ...) - (gep X, ...)
+      if (RHSGEP->getOperand(0)->stripPointerCasts() ==
+            LHSGEP->getOperand(0)->stripPointerCasts()) {
+        GEP2 = LHSGEP;
+        GEP1 = RHSGEP;
+        Swapped = true;
       }
     }
   }
 
   if (!GEP1)
+    // No GEP found.
     return nullptr;
 
   if (GEP2) {
@@ -1696,7 +1712,7 @@ Value *InstCombinerImpl::OptimizePointerDifference(Value *LHS, Value *RHS,
   // pointer, subtract it from the offset we have.
   if (GEP2) {
     Value *Offset = EmitGEPOffset(GEP2);
-    Result = Builder.CreateSub(Result, Offset, "gepdiff");
+    Result = Builder.CreateSub(Result, Offset);
   }
 
   // If we have p - gep(p, ...)  then we have to negate the result.
diff --git a/llvm/lib/Transforms/InstCombine/InstCombineNegator.cpp b/llvm/lib/Transforms/InstCombine/InstCombineNegator.cpp
index b321eab01d7..9fe8fea725c 100644
--- a/llvm/lib/Transforms/InstCombine/InstCombineNegator.cpp
+++ b/llvm/lib/Transforms/InstCombine/InstCombineNegator.cpp
@@ -348,16 +348,10 @@ LLVM_NODISCARD Value *Negator::visitImpl(Value *V, unsigned Depth) {
   }
   case Instruction::Shl: {
     // `shl` is negatible if the first operand is negatible.
-    if (Value *NegOp0 = negate(I->getOperand(0), Depth + 1))
-      return Builder.CreateShl(NegOp0, I->getOperand(1), I->getName() + ".neg");
-    // Otherwise, `shl %x, C` can be interpreted as `mul %x, 1<<C`.
-    auto *Op1C = dyn_cast<Constant>(I->getOperand(1));
-    if (!Op1C) // Early return.
+    Value *NegOp0 = negate(I->getOperand(0), Depth + 1);
+    if (!NegOp0) // Early return.
       return nullptr;
-    return Builder.CreateMul(
-        I->getOperand(0),
-        ConstantExpr::getShl(Constant::getAllOnesValue(Op1C->getType()), Op1C),
-        I->getName() + ".neg");
+    return Builder.CreateShl(NegOp0, I->getOperand(1), I->getName() + ".neg");
   }
   case Instruction::Or: {
     if (!haveNoCommonBitsSet(I->getOperand(0), I->getOperand(1), DL, &AC, I,
@@ -373,32 +367,13 @@ LLVM_NODISCARD Value *Negator::visitImpl(Value *V, unsigned Depth) {
   }
   case Instruction::Add: {
     // `add` is negatible if both of its operands are negatible.
-    SmallVector<Value *, 2> NegatedOps, NonNegatedOps;
-    for (Value *Op : I->operands()) {
-      // Can we sink the negation into this operand?
-      if (Value *NegOp = negate(Op, Depth + 1)) {
-        NegatedOps.emplace_back(NegOp); // Successfully negated operand!
-        continue;
-      }
-      // Failed to sink negation into this operand. IFF we started from negation
-      // and we manage to sink negation into one operand, we can still do this.
-      if (!IsTrulyNegation)
-        return nullptr;
-      NonNegatedOps.emplace_back(Op); // Just record which operand that was.
-    }
-    assert((NegatedOps.size() + NonNegatedOps.size()) == 2 &&
-           "Internal consistency sanity check.");
-    // Did we manage to sink negation into both of the operands?
-    if (NegatedOps.size() == 2) // Then we get to keep the `add`!
-      return Builder.CreateAdd(NegatedOps[0], NegatedOps[1],
-                               I->getName() + ".neg");
-    assert(IsTrulyNegation && "We should have early-exited then.");
-    // Completely failed to sink negation?
-    if (NonNegatedOps.size() == 2)
+    Value *NegOp0 = negate(I->getOperand(0), Depth + 1);
+    if (!NegOp0) // Early return.
       return nullptr;
-    // 0-(a+b) --> (-a)-b
-    return Builder.CreateSub(NegatedOps[0], NonNegatedOps[0],
-                             I->getName() + ".neg");
+    Value *NegOp1 = negate(I->getOperand(1), Depth + 1);
+    if (!NegOp1)
+      return nullptr;
+    return Builder.CreateAdd(NegOp0, NegOp1, I->getName() + ".neg");
   }
   case Instruction::Xor: {
     std::array<Value *, 2> Ops = getSortedOperandsOfBinOp(I);
diff --git a/llvm/test/CodeGen/AMDGPU/reqd-work-group-size.ll b/llvm/test/CodeGen/AMDGPU/reqd-work-group-size.ll
index 40b1db00dcd..1e69d455135 100644
--- a/llvm/test/CodeGen/AMDGPU/reqd-work-group-size.ll
+++ b/llvm/test/CodeGen/AMDGPU/reqd-work-group-size.ll
@@ -149,7 +149,7 @@ define amdgpu_kernel void @use_local_size_z_8_16_2(i64 addrspace(1)* %out) #0 !r
 
 ; CHECK-LABEL: @local_size_x_8_16_2_wrong_group_id(
 ; CHECK: %group.id = tail call i32 @llvm.amdgcn.workgroup.id.y()
-; CHECK: %group.id_x_group.size.x.neg = mul i32 %group.id, -8
+; CHECK: %group.id_x_group.size.x = shl i32 %group.id, 3
 define amdgpu_kernel void @local_size_x_8_16_2_wrong_group_id(i64 addrspace(1)* %out) #0 !reqd_work_group_size !0 {
   %dispatch.ptr = tail call i8 addrspace(4)* @llvm.amdgcn.dispatch.ptr()
   %gep.group.size.x = getelementptr inbounds i8, i8 addrspace(4)* %dispatch.ptr, i64 4
@@ -172,7 +172,8 @@ define amdgpu_kernel void @local_size_x_8_16_2_wrong_group_id(i64 addrspace(1)*
 ; CHECK-LABEL: @local_size_x_8_16_2_wrong_grid_size(
 ; CHECK: %grid.size.x = load i32, i32 addrspace(4)* %gep.grid.size.x.bc, align 4
 ; CHECK: %group.id = tail call i32 @llvm.amdgcn.workgroup.id.x()
-; CHECK: %group.id_x_group.size.x.neg = mul i32 %group.id, -8
+; CHECK: %group.id_x_group.size.x = shl i32 %group.id, 3
+; CHECK: %sub = sub i32 %grid.size.x, %group.id_x_group.size.x
   define amdgpu_kernel void @local_size_x_8_16_2_wrong_grid_size(i64 addrspace(1)* %out) #0 !reqd_work_group_size !0 {
   %dispatch.ptr = tail call i8 addrspace(4)* @llvm.amdgcn.dispatch.ptr()
   %gep.group.size.x = getelementptr inbounds i8, i8 addrspace(4)* %dispatch.ptr, i64 4
@@ -195,8 +196,8 @@ define amdgpu_kernel void @local_size_x_8_16_2_wrong_group_id(i64 addrspace(1)*
 ; CHECK-LABEL: @local_size_x_8_16_2_wrong_cmp_type(
 ; CHECK: %grid.size.x = load i32, i32 addrspace(4)* %gep.grid.size.x.bc, align 4
 ; CHECK: %group.id = tail call i32 @llvm.amdgcn.workgroup.id.x()
-; CHECK: %group.id_x_group.size.x.neg = mul i32 %group.id, -8
-; CHECK: %sub = add i32 %group.id_x_group.size.x.neg, %grid.size.x
+; CHECK: %group.id_x_group.size.x = shl i32 %group.id, 3
+; CHECK: %sub = sub i32 %grid.size.x, %group.id_x_group.size.x
 ; CHECK: %cmp = icmp slt i32 %sub, 8
 ; CHECK: %select = select i1 %cmp, i32 %sub, i32 8
 define amdgpu_kernel void @local_size_x_8_16_2_wrong_cmp_type(i64 addrspace(1)* %out) #0 !reqd_work_group_size !0 {
@@ -219,8 +220,8 @@ define amdgpu_kernel void @local_size_x_8_16_2_wrong_cmp_type(i64 addrspace(1)*
 }
 
 ; CHECK-LABEL: @local_size_x_8_16_2_wrong_select(
-; CHECK: %group.id_x_group.size.x.neg = mul i32 %group.id, -8
-; CHECK: %sub = add i32 %group.id_x_group.size.x.neg, %grid.size.x
+; CHECK: %group.id_x_group.size.x = shl i32 %group.id, 3
+; CHECK: %sub = sub i32 %grid.size.x, %group.id_x_group.size.x
 ; CHECK: %1 = icmp ugt i32 %sub, 8
 ; CHECK: %select = select i1 %1, i32 %sub, i32 8
 ; CHECK: %zext = zext i32 %select to i64
@@ -247,8 +248,8 @@ define amdgpu_kernel void @local_size_x_8_16_2_wrong_select(i64 addrspace(1)* %o
 ; CHECK: %grid.size.x = load i16, i16 addrspace(4)* %gep.grid.size.x.bc, align 4
 ; CHECK: %grid.size.x.zext = zext i16 %grid.size.x to i32
 ; CHECK: %group.id = tail call i32 @llvm.amdgcn.workgroup.id.x()
-; CHECK: %group.id_x_group.size.x.neg = mul i32 %group.id, -8
-; CHECK: %sub = add i32 %group.id_x_group.size.x.neg, %grid.size.x.zext
+; CHECK: %group.id_x_group.size.x = shl i32 %group.id, 3
+; CHECK: %sub = sub i32 %grid.size.x.zext, %group.id_x_group.size.x
 define amdgpu_kernel void @use_local_size_x_8_16_2_wrong_grid_load_size(i64 addrspace(1)* %out) #0 !reqd_work_group_size !0 {
   %dispatch.ptr = tail call i8 addrspace(4)* @llvm.amdgcn.dispatch.ptr()
   %gep.group.size.x = getelementptr inbounds i8, i8 addrspace(4)* %dispatch.ptr, i64 4
diff --git a/llvm/test/Transforms/InstCombine/icmp.ll b/llvm/test/Transforms/InstCombine/icmp.ll
index 68351812178..4f5ba0a6e68 100644
--- a/llvm/test/Transforms/InstCombine/icmp.ll
+++ b/llvm/test/Transforms/InstCombine/icmp.ll
@@ -514,8 +514,7 @@ define i1 @test24(i64 %i) {
 ; unsigned overflow does not happen during offset computation
 define i1 @test24_neg_offs(i32* %p, i64 %offs) {
 ; CHECK-LABEL: @test24_neg_offs(
-; CHECK-NEXT:    [[P1_IDX_NEG:%.*]] = mul i64 [[OFFS:%.*]], -4
-; CHECK-NEXT:    [[CMP:%.*]] = icmp eq i64 [[P1_IDX_NEG]], 8
+; CHECK-NEXT:    [[CMP:%.*]] = icmp eq i64 [[OFFS:%.*]], -2
 ; CHECK-NEXT:    ret i1 [[CMP]]
 ;
   %p1 = getelementptr inbounds i32, i32* %p, i64 %offs
diff --git a/llvm/test/Transforms/InstCombine/sub-gep.ll b/llvm/test/Transforms/InstCombine/sub-gep.ll
index ce9657433bb..51eb994bf34 100644
--- a/llvm/test/Transforms/InstCombine/sub-gep.ll
+++ b/llvm/test/Transforms/InstCombine/sub-gep.ll
@@ -1,8 +1,6 @@
 ; NOTE: Assertions have been autogenerated by utils/update_test_checks.py
 ; RUN: opt -S -instcombine < %s | FileCheck %s
 
-target datalayout = "e-p:64:64:64-p1:16:16:16-i1:8:8-i8:8:8-i16:16:16-i32:32:32-i64:64:64-f32:32:32-f64:64:64-v64:64:64-v128:128:128-a0:0:64-s0:64:64-f80:128:128"
-
 define i64 @test_inbounds([0 x i32]* %base, i64 %idx) {
 ; CHECK-LABEL: @test_inbounds(
 ; CHECK-NEXT:    [[P2_IDX:%.*]] = shl nsw i64 [[IDX:%.*]], 2
@@ -16,32 +14,6 @@ define i64 @test_inbounds([0 x i32]* %base, i64 %idx) {
   ret i64 %d
 }
 
-define i64 @test_partial_inbounds1([0 x i32]* %base, i64 %idx) {
-; CHECK-LABEL: @test_partial_inbounds1(
-; CHECK-NEXT:    [[P2_IDX:%.*]] = shl i64 [[IDX:%.*]], 2
-; CHECK-NEXT:    ret i64 [[P2_IDX]]
-;
-  %p1 = getelementptr inbounds [0 x i32], [0 x i32]* %base, i64 0, i64 0
-  %p2 = getelementptr [0 x i32], [0 x i32]* %base, i64 0, i64 %idx
-  %i1 = ptrtoint i32* %p1 to i64
-  %i2 = ptrtoint i32* %p2 to i64
-  %d = sub i64 %i2, %i1
-  ret i64 %d
-}
-
-define i64 @test_partial_inbounds2([0 x i32]* %base, i64 %idx) {
-; CHECK-LABEL: @test_partial_inbounds2(
-; CHECK-NEXT:    [[P2_IDX:%.*]] = shl nsw i64 [[IDX:%.*]], 2
-; CHECK-NEXT:    ret i64 [[P2_IDX]]
-;
-  %p1 = getelementptr [0 x i32], [0 x i32]* %base, i64 0, i64 0
-  %p2 = getelementptr inbounds [0 x i32], [0 x i32]* %base, i64 0, i64 %idx
-  %i1 = ptrtoint i32* %p1 to i64
-  %i2 = ptrtoint i32* %p2 to i64
-  %d = sub i64 %i2, %i1
-  ret i64 %d
-}
-
 define i64 @test_inbounds_nuw([0 x i32]* %base, i64 %idx) {
 ; CHECK-LABEL: @test_inbounds_nuw(
 ; CHECK-NEXT:    [[P2_IDX:%.*]] = shl nuw nsw i64 [[IDX:%.*]], 2
@@ -86,36 +58,11 @@ define i32 @test_inbounds_nuw_trunc([0 x i32]* %base, i64 %idx) {
 
 define i64 @test_inbounds_nuw_swapped([0 x i32]* %base, i64 %idx) {
 ; CHECK-LABEL: @test_inbounds_nuw_swapped(
-; CHECK-NEXT:    [[P2_IDX_NEG:%.*]] = mul i64 [[IDX:%.*]], -4
-; CHECK-NEXT:    ret i64 [[P2_IDX_NEG]]
-;
-  %p1 = getelementptr inbounds [0 x i32], [0 x i32]* %base, i64 0, i64 0
-  %p2 = getelementptr inbounds [0 x i32], [0 x i32]* %base, i64 0, i64 %idx
-  %i1 = ptrtoint i32* %p2 to i64
-  %i2 = ptrtoint i32* %p1 to i64
-  %d = sub nuw i64 %i2, %i1
-  ret i64 %d
-}
-
-define i64 @test_inbounds1_nuw_swapped([0 x i32]* %base, i64 %idx) {
-; CHECK-LABEL: @test_inbounds1_nuw_swapped(
-; CHECK-NEXT:    [[P2_IDX_NEG:%.*]] = mul i64 [[IDX:%.*]], -4
-; CHECK-NEXT:    ret i64 [[P2_IDX_NEG]]
+; CHECK-NEXT:    [[P2_IDX:%.*]] = shl nsw i64 [[IDX:%.*]], 2
+; CHECK-NEXT:    [[DIFF_NEG:%.*]] = sub i64 0, [[P2_IDX]]
+; CHECK-NEXT:    ret i64 [[DIFF_NEG]]
 ;
   %p1 = getelementptr inbounds [0 x i32], [0 x i32]* %base, i64 0, i64 0
-  %p2 = getelementptr [0 x i32], [0 x i32]* %base, i64 0, i64 %idx
-  %i1 = ptrtoint i32* %p2 to i64
-  %i2 = ptrtoint i32* %p1 to i64
-  %d = sub nuw i64 %i2, %i1
-  ret i64 %d
-}
-
-define i64 @test_inbounds2_nuw_swapped([0 x i32]* %base, i64 %idx) {
-; CHECK-LABEL: @test_inbounds2_nuw_swapped(
-; CHECK-NEXT:    [[P2_IDX_NEG:%.*]] = mul i64 [[IDX:%.*]], -4
-; CHECK-NEXT:    ret i64 [[P2_IDX_NEG]]
-;
-  %p1 = getelementptr [0 x i32], [0 x i32]* %base, i64 0, i64 0
   %p2 = getelementptr inbounds [0 x i32], [0 x i32]* %base, i64 0, i64 %idx
   %i1 = ptrtoint i32* %p2 to i64
   %i2 = ptrtoint i32* %p1 to i64
@@ -126,10 +73,9 @@ define i64 @test_inbounds2_nuw_swapped([0 x i32]* %base, i64 %idx) {
 ; The sub and shl here could be nuw, but this is harder to handle.
 define i64 @test_inbounds_nuw_two_gep([0 x i32]* %base, i64 %idx, i64 %idx2) {
 ; CHECK-LABEL: @test_inbounds_nuw_two_gep(
-; CHECK-NEXT:    [[P2_IDX:%.*]] = shl nsw i64 [[IDX2:%.*]], 2
-; CHECK-NEXT:    [[P1_IDX_NEG:%.*]] = mul i64 [[IDX:%.*]], -4
-; CHECK-NEXT:    [[GEPDIFF:%.*]] = add i64 [[P1_IDX_NEG]], [[P2_IDX]]
-; CHECK-NEXT:    ret i64 [[GEPDIFF]]
+; CHECK-NEXT:    [[P1_IDX1_NEG:%.*]] = sub i64 [[IDX2:%.*]], [[IDX:%.*]]
+; CHECK-NEXT:    [[DOTNEG:%.*]] = shl i64 [[P1_IDX1_NEG]], 2
+; CHECK-NEXT:    ret i64 [[DOTNEG]]
 ;
   %p1 = getelementptr inbounds [0 x i32], [0 x i32]* %base, i64 0, i64 %idx
   %p2 = getelementptr inbounds [0 x i32], [0 x i32]* %base, i64 0, i64 %idx2
@@ -153,187 +99,3 @@ define i64 @test_inbounds_nuw_multi_index([0 x [2 x i32]]* %base, i64 %idx, i64
   %d = sub nuw i64 %i2, %i1
   ret i64 %d
 }
-
-; rdar://7362831
-define i32 @test23(i8* %P, i64 %A){
-; CHECK-LABEL: @test23(
-; CHECK-NEXT:    [[TMP1:%.*]] = trunc i64 [[A:%.*]] to i32
-; CHECK-NEXT:    ret i32 [[TMP1]]
-;
-  %B = getelementptr inbounds i8, i8* %P, i64 %A
-  %C = ptrtoint i8* %B to i64
-  %D = trunc i64 %C to i32
-  %E = ptrtoint i8* %P to i64
-  %F = trunc i64 %E to i32
-  %G = sub i32 %D, %F
-  ret i32 %G
-}
-
-define i8 @test23_as1(i8 addrspace(1)* %P, i16 %A) {
-; CHECK-LABEL: @test23_as1(
-; CHECK-NEXT:    [[TMP1:%.*]] = trunc i16 [[A:%.*]] to i8
-; CHECK-NEXT:    ret i8 [[TMP1]]
-;
-  %B = getelementptr inbounds i8, i8 addrspace(1)* %P, i16 %A
-  %C = ptrtoint i8 addrspace(1)* %B to i16
-  %D = trunc i16 %C to i8
-  %E = ptrtoint i8 addrspace(1)* %P to i16
-  %F = trunc i16 %E to i8
-  %G = sub i8 %D, %F
-  ret i8 %G
-}
-
-define i64 @test24(i8* %P, i64 %A){
-; CHECK-LABEL: @test24(
-; CHECK-NEXT:    ret i64 [[A:%.*]]
-;
-  %B = getelementptr inbounds i8, i8* %P, i64 %A
-  %C = ptrtoint i8* %B to i64
-  %E = ptrtoint i8* %P to i64
-  %G = sub i64 %C, %E
-  ret i64 %G
-}
-
-define i16 @test24_as1(i8 addrspace(1)* %P, i16 %A) {
-; CHECK-LABEL: @test24_as1(
-; CHECK-NEXT:    ret i16 [[A:%.*]]
-;
-  %B = getelementptr inbounds i8, i8 addrspace(1)* %P, i16 %A
-  %C = ptrtoint i8 addrspace(1)* %B to i16
-  %E = ptrtoint i8 addrspace(1)* %P to i16
-  %G = sub i16 %C, %E
-  ret i16 %G
-}
-
-define i64 @test24a(i8* %P, i64 %A){
-; CHECK-LABEL: @test24a(
-; CHECK-NEXT:    [[DIFF_NEG:%.*]] = sub i64 0, [[A:%.*]]
-; CHECK-NEXT:    ret i64 [[DIFF_NEG]]
-;
-  %B = getelementptr inbounds i8, i8* %P, i64 %A
-  %C = ptrtoint i8* %B to i64
-  %E = ptrtoint i8* %P to i64
-  %G = sub i64 %E, %C
-  ret i64 %G
-}
-
-define i16 @test24a_as1(i8 addrspace(1)* %P, i16 %A) {
-; CHECK-LABEL: @test24a_as1(
-; CHECK-NEXT:    [[DIFF_NEG:%.*]] = sub i16 0, [[A:%.*]]
-; CHECK-NEXT:    ret i16 [[DIFF_NEG]]
-;
-  %B = getelementptr inbounds i8, i8 addrspace(1)* %P, i16 %A
-  %C = ptrtoint i8 addrspace(1)* %B to i16
-  %E = ptrtoint i8 addrspace(1)* %P to i16
-  %G = sub i16 %E, %C
-  ret i16 %G
-}
-
-@Arr = external global [42 x i16]
-
-define i64 @test24b(i8* %P, i64 %A){
-; CHECK-LABEL: @test24b(
-; CHECK-NEXT:    [[B_IDX:%.*]] = shl nsw i64 [[A:%.*]], 1
-; CHECK-NEXT:    ret i64 [[B_IDX]]
-;
-  %B = getelementptr inbounds [42 x i16], [42 x i16]* @Arr, i64 0, i64 %A
-  %C = ptrtoint i16* %B to i64
-  %G = sub i64 %C, ptrtoint ([42 x i16]* @Arr to i64)
-  ret i64 %G
-}
-
-define i64 @test25(i8* %P, i64 %A){
-; CHECK-LABEL: @test25(
-; CHECK-NEXT:    [[B_IDX:%.*]] = shl nsw i64 [[A:%.*]], 1
-; CHECK-NEXT:    [[GEPDIFF:%.*]] = add i64 [[B_IDX]], -84
-; CHECK-NEXT:    ret i64 [[GEPDIFF]]
-;
-  %B = getelementptr inbounds [42 x i16], [42 x i16]* @Arr, i64 0, i64 %A
-  %C = ptrtoint i16* %B to i64
-  %G = sub i64 %C, ptrtoint (i16* getelementptr ([42 x i16], [42 x i16]* @Arr, i64 1, i64 0) to i64)
-  ret i64 %G
-}
-
-@Arr_as1 = external addrspace(1) global [42 x i16]
-
-define i16 @test25_as1(i8 addrspace(1)* %P, i64 %A) {
-; CHECK-LABEL: @test25_as1(
-; CHECK-NEXT:    [[TMP1:%.*]] = trunc i64 [[A:%.*]] to i16
-; CHECK-NEXT:    [[B_IDX:%.*]] = shl nsw i16 [[TMP1]], 1
-; CHECK-NEXT:    [[GEPDIFF:%.*]] = add i16 [[B_IDX]], -84
-; CHECK-NEXT:    ret i16 [[GEPDIFF]]
-;
-  %B = getelementptr inbounds [42 x i16], [42 x i16] addrspace(1)* @Arr_as1, i64 0, i64 %A
-  %C = ptrtoint i16 addrspace(1)* %B to i16
-  %G = sub i16 %C, ptrtoint (i16 addrspace(1)* getelementptr ([42 x i16], [42 x i16] addrspace(1)* @Arr_as1, i64 1, i64 0) to i16)
-  ret i16 %G
-}
-
-define i64 @test30(i8* %foo, i64 %i, i64 %j) {
-; CHECK-LABEL: @test30(
-; CHECK-NEXT:    [[GEP1_IDX:%.*]] = shl nsw i64 [[I:%.*]], 2
-; CHECK-NEXT:    [[GEPDIFF:%.*]] = sub i64 [[GEP1_IDX]], [[J:%.*]]
-; CHECK-NEXT:    ret i64 [[GEPDIFF]]
-;
-  %bit = bitcast i8* %foo to i32*
-  %gep1 = getelementptr inbounds i32, i32* %bit, i64 %i
-  %gep2 = getelementptr inbounds i8, i8* %foo, i64 %j
-  %cast1 = ptrtoint i32* %gep1 to i64
-  %cast2 = ptrtoint i8* %gep2 to i64
-  %sub = sub i64 %cast1, %cast2
-  ret i64 %sub
-}
-
-define i16 @test30_as1(i8 addrspace(1)* %foo, i16 %i, i16 %j) {
-; CHECK-LABEL: @test30_as1(
-; CHECK-NEXT:    [[GEP1_IDX:%.*]] = shl nsw i16 [[I:%.*]], 2
-; CHECK-NEXT:    [[GEPDIFF:%.*]] = sub i16 [[GEP1_IDX]], [[J:%.*]]
-; CHECK-NEXT:    ret i16 [[GEPDIFF]]
-;
-  %bit = bitcast i8 addrspace(1)* %foo to i32 addrspace(1)*
-  %gep1 = getelementptr inbounds i32, i32 addrspace(1)* %bit, i16 %i
-  %gep2 = getelementptr inbounds i8, i8 addrspace(1)* %foo, i16 %j
-  %cast1 = ptrtoint i32 addrspace(1)* %gep1 to i16
-  %cast2 = ptrtoint i8 addrspace(1)* %gep2 to i16
-  %sub = sub i16 %cast1, %cast2
-  ret i16 %sub
-}
-
-define i64 @gep_diff_both_inbounds(i8* %foo, i64 %i, i64 %j) {
-; CHECK-LABEL: @gep_diff_both_inbounds(
-; CHECK-NEXT:    [[GEPDIFF:%.*]] = sub i64 [[I:%.*]], [[J:%.*]]
-; CHECK-NEXT:    ret i64 [[GEPDIFF]]
-;
-  %gep1 = getelementptr inbounds i8, i8* %foo, i64 %i
-  %gep2 = getelementptr inbounds i8, i8* %foo, i64 %j
-  %cast1 = ptrtoint i8* %gep1 to i64
-  %cast2 = ptrtoint i8* %gep2 to i64
-  %sub = sub i64 %cast1, %cast2
-  ret i64 %sub
-}
-
-define i64 @gep_diff_first_inbounds(i8* %foo, i64 %i, i64 %j) {
-; CHECK-LABEL: @gep_diff_first_inbounds(
-; CHECK-NEXT:    [[GEPDIFF:%.*]] = sub i64 [[I:%.*]], [[J:%.*]]
-; CHECK-NEXT:    ret i64 [[GEPDIFF]]
-;
-  %gep1 = getelementptr inbounds i8, i8* %foo, i64 %i
-  %gep2 = getelementptr i8, i8* %foo, i64 %j
-  %cast1 = ptrtoint i8* %gep1 to i64
-  %cast2 = ptrtoint i8* %gep2 to i64
-  %sub = sub i64 %cast1, %cast2
-  ret i64 %sub
-}
-
-define i64 @gep_diff_second_inbounds(i8* %foo, i64 %i, i64 %j) {
-; CHECK-LABEL: @gep_diff_second_inbounds(
-; CHECK-NEXT:    [[GEPDIFF:%.*]] = sub i64 [[I:%.*]], [[J:%.*]]
-; CHECK-NEXT:    ret i64 [[GEPDIFF]]
-;
-  %gep1 = getelementptr i8, i8* %foo, i64 %i
-  %gep2 = getelementptr inbounds i8, i8* %foo, i64 %j
-  %cast1 = ptrtoint i8* %gep1 to i64
-  %cast2 = ptrtoint i8* %gep2 to i64
-  %sub = sub i64 %cast1, %cast2
-  ret i64 %sub
-}
diff --git a/llvm/test/Transforms/InstCombine/sub-of-negatible.ll b/llvm/test/Transforms/InstCombine/sub-of-negatible.ll
index 3d988c9f3d4..83ebfb0f378 100644
--- a/llvm/test/Transforms/InstCombine/sub-of-negatible.ll
+++ b/llvm/test/Transforms/InstCombine/sub-of-negatible.ll
@@ -1076,8 +1076,8 @@ define i8 @negate_left_shift_by_constant(i8 %x, i8 %y, i8 %z, i8 %k) {
 ; CHECK-LABEL: @negate_left_shift_by_constant(
 ; CHECK-NEXT:    [[T0:%.*]] = sub i8 [[K:%.*]], [[Z:%.*]]
 ; CHECK-NEXT:    call void @use8(i8 [[T0]])
-; CHECK-NEXT:    [[T1_NEG:%.*]] = mul i8 [[T0]], -16
-; CHECK-NEXT:    [[T2:%.*]] = add i8 [[T1_NEG]], [[X:%.*]]
+; CHECK-NEXT:    [[T1:%.*]] = shl i8 [[T0]], 4
+; CHECK-NEXT:    [[T2:%.*]] = sub i8 [[X:%.*]], [[T1]]
 ; CHECK-NEXT:    ret i8 [[T2]]
 ;
   %t0 = sub i8 %k, %z
@@ -1106,8 +1106,9 @@ define i8 @negate_left_shift_by_constant_extrause(i8 %x, i8 %y, i8 %z, i8 %k) {
 ; `add` with single negatible operand is still negatible
 define i8 @negate_add_with_single_negatible_operand(i8 %x, i8 %y) {
 ; CHECK-LABEL: @negate_add_with_single_negatible_operand(
-; CHECK-NEXT:    [[T0_NEG:%.*]] = sub i8 -42, [[X:%.*]]
-; CHECK-NEXT:    ret i8 [[T0_NEG]]
+; CHECK-NEXT:    [[T0:%.*]] = add i8 [[X:%.*]], 42
+; CHECK-NEXT:    [[T1:%.*]] = sub i8 0, [[T0]]
+; CHECK-NEXT:    ret i8 [[T1]]
 ;
   %t0 = add i8 %x, 42
   %t1 = sub i8 0, %t0
@@ -1138,7 +1139,6 @@ define i8 @negate_add_with_single_negatible_operand_extrause(i8 %x, i8 %y) {
   %t1 = sub i8 0, %t0
   ret i8 %t1
 }
-; But don't do this if that means just sinking the negation.
 define i8 @negate_add_with_single_negatible_operand_non_negation(i8 %x, i8 %y) {
 ; CHECK-LABEL: @negate_add_with_single_negatible_operand_non_negation(
 ; CHECK-NEXT:    [[T0:%.*]] = add i8 [[X:%.*]], 42
diff --git a/llvm/test/Transforms/InstCombine/sub.ll b/llvm/test/Transforms/InstCombine/sub.ll
index 98d8a9e6b5c..3bc8b67649f 100644
--- a/llvm/test/Transforms/InstCombine/sub.ll
+++ b/llvm/test/Transforms/InstCombine/sub.ll
@@ -414,6 +414,123 @@ define zeroext i1 @test22(i32 %a, i32 %b)  nounwind  {
   ret i1 %i5
 }
 
+; rdar://7362831
+define i32 @test23(i8* %P, i64 %A){
+; CHECK-LABEL: @test23(
+; CHECK-NEXT:    [[TMP1:%.*]] = trunc i64 [[A:%.*]] to i32
+; CHECK-NEXT:    ret i32 [[TMP1]]
+;
+  %B = getelementptr inbounds i8, i8* %P, i64 %A
+  %C = ptrtoint i8* %B to i64
+  %D = trunc i64 %C to i32
+  %E = ptrtoint i8* %P to i64
+  %F = trunc i64 %E to i32
+  %G = sub i32 %D, %F
+  ret i32 %G
+}
+
+define i8 @test23_as1(i8 addrspace(1)* %P, i16 %A) {
+; CHECK-LABEL: @test23_as1(
+; CHECK-NEXT:    [[TMP1:%.*]] = trunc i16 [[A:%.*]] to i8
+; CHECK-NEXT:    ret i8 [[TMP1]]
+;
+  %B = getelementptr inbounds i8, i8 addrspace(1)* %P, i16 %A
+  %C = ptrtoint i8 addrspace(1)* %B to i16
+  %D = trunc i16 %C to i8
+  %E = ptrtoint i8 addrspace(1)* %P to i16
+  %F = trunc i16 %E to i8
+  %G = sub i8 %D, %F
+  ret i8 %G
+}
+
+define i64 @test24(i8* %P, i64 %A){
+; CHECK-LABEL: @test24(
+; CHECK-NEXT:    ret i64 [[A:%.*]]
+;
+  %B = getelementptr inbounds i8, i8* %P, i64 %A
+  %C = ptrtoint i8* %B to i64
+  %E = ptrtoint i8* %P to i64
+  %G = sub i64 %C, %E
+  ret i64 %G
+}
+
+define i16 @test24_as1(i8 addrspace(1)* %P, i16 %A) {
+; CHECK-LABEL: @test24_as1(
+; CHECK-NEXT:    ret i16 [[A:%.*]]
+;
+  %B = getelementptr inbounds i8, i8 addrspace(1)* %P, i16 %A
+  %C = ptrtoint i8 addrspace(1)* %B to i16
+  %E = ptrtoint i8 addrspace(1)* %P to i16
+  %G = sub i16 %C, %E
+  ret i16 %G
+}
+
+define i64 @test24a(i8* %P, i64 %A){
+; CHECK-LABEL: @test24a(
+; CHECK-NEXT:    [[DIFF_NEG:%.*]] = sub i64 0, [[A:%.*]]
+; CHECK-NEXT:    ret i64 [[DIFF_NEG]]
+;
+  %B = getelementptr inbounds i8, i8* %P, i64 %A
+  %C = ptrtoint i8* %B to i64
+  %E = ptrtoint i8* %P to i64
+  %G = sub i64 %E, %C
+  ret i64 %G
+}
+
+define i16 @test24a_as1(i8 addrspace(1)* %P, i16 %A) {
+; CHECK-LABEL: @test24a_as1(
+; CHECK-NEXT:    [[DIFF_NEG:%.*]] = sub i16 0, [[A:%.*]]
+; CHECK-NEXT:    ret i16 [[DIFF_NEG]]
+;
+  %B = getelementptr inbounds i8, i8 addrspace(1)* %P, i16 %A
+  %C = ptrtoint i8 addrspace(1)* %B to i16
+  %E = ptrtoint i8 addrspace(1)* %P to i16
+  %G = sub i16 %E, %C
+  ret i16 %G
+}
+
+
+@Arr = external global [42 x i16]
+
+define i64 @test24b(i8* %P, i64 %A){
+; CHECK-LABEL: @test24b(
+; CHECK-NEXT:    [[B_IDX:%.*]] = shl nsw i64 [[A:%.*]], 1
+; CHECK-NEXT:    ret i64 [[B_IDX]]
+;
+  %B = getelementptr inbounds [42 x i16], [42 x i16]* @Arr, i64 0, i64 %A
+  %C = ptrtoint i16* %B to i64
+  %G = sub i64 %C, ptrtoint ([42 x i16]* @Arr to i64)
+  ret i64 %G
+}
+
+
+define i64 @test25(i8* %P, i64 %A){
+; CHECK-LABEL: @test25(
+; CHECK-NEXT:    [[B_IDX:%.*]] = shl nsw i64 [[A:%.*]], 1
+; CHECK-NEXT:    [[DOTNEG:%.*]] = add i64 [[B_IDX]], -84
+; CHECK-NEXT:    ret i64 [[DOTNEG]]
+;
+  %B = getelementptr inbounds [42 x i16], [42 x i16]* @Arr, i64 0, i64 %A
+  %C = ptrtoint i16* %B to i64
+  %G = sub i64 %C, ptrtoint (i16* getelementptr ([42 x i16], [42 x i16]* @Arr, i64 1, i64 0) to i64)
+  ret i64 %G
+}
+
+@Arr_as1 = external addrspace(1) global [42 x i16]
+
+define i16 @test25_as1(i8 addrspace(1)* %P, i64 %A) {
+; CHECK-LABEL: @test25_as1(
+; CHECK-NEXT:    [[TMP1:%.*]] = trunc i64 [[A:%.*]] to i16
+; CHECK-NEXT:    [[B_IDX:%.*]] = shl nsw i16 [[TMP1]], 1
+; CHECK-NEXT:    [[DOTNEG:%.*]] = add i16 [[B_IDX]], -84
+; CHECK-NEXT:    ret i16 [[DOTNEG]]
+;
+  %B = getelementptr inbounds [42 x i16], [42 x i16] addrspace(1)* @Arr_as1, i64 0, i64 %A
+  %C = ptrtoint i16 addrspace(1)* %B to i16
+  %G = sub i16 %C, ptrtoint (i16 addrspace(1)* getelementptr ([42 x i16], [42 x i16] addrspace(1)* @Arr_as1, i64 1, i64 0) to i16)
+  ret i16 %G
+}
+
 define i32 @test26(i32 %x) {
 ; CHECK-LABEL: @test26(
 ; CHECK-NEXT:    [[SHL_NEG:%.*]] = shl i32 -3, [[X:%.*]]
@@ -440,8 +557,9 @@ define i64 @test_neg_shl_sub_extra_use1(i64 %a, i64 %b, i64* %p) {
 ; CHECK-LABEL: @test_neg_shl_sub_extra_use1(
 ; CHECK-NEXT:    [[SUB:%.*]] = sub i64 [[A:%.*]], [[B:%.*]]
 ; CHECK-NEXT:    store i64 [[SUB]], i64* [[P:%.*]], align 8
-; CHECK-NEXT:    [[MUL_NEG:%.*]] = mul i64 [[SUB]], -4
-; CHECK-NEXT:    ret i64 [[MUL_NEG]]
+; CHECK-NEXT:    [[MUL:%.*]] = shl i64 [[SUB]], 2
+; CHECK-NEXT:    [[NEG:%.*]] = sub i64 0, [[MUL]]
+; CHECK-NEXT:    ret i64 [[NEG]]
 ;
   %sub = sub i64 %a, %b
   store i64 %sub, i64* %p
@@ -707,6 +825,49 @@ define i32 @test28commuted(i32 %x, i32 %y, i32 %z) {
   ret i32 %sub
 }
 
+define i64 @test29(i8* %foo, i64 %i, i64 %j) {
+; CHECK-LABEL: @test29(
+; CHECK-NEXT:    [[DOTNEG:%.*]] = sub i64 [[I:%.*]], [[J:%.*]]
+; CHECK-NEXT:    ret i64 [[DOTNEG]]
+;
+  %gep1 = getelementptr inbounds i8, i8* %foo, i64 %i
+  %gep2 = getelementptr inbounds i8, i8* %foo, i64 %j
+  %cast1 = ptrtoint i8* %gep1 to i64
+  %cast2 = ptrtoint i8* %gep2 to i64
+  %sub = sub i64 %cast1, %cast2
+  ret i64 %sub
+}
+
+define i64 @test30(i8* %foo, i64 %i, i64 %j) {
+; CHECK-LABEL: @test30(
+; CHECK-NEXT:    [[GEP1_IDX:%.*]] = shl nsw i64 [[I:%.*]], 2
+; CHECK-NEXT:    [[DOTNEG:%.*]] = sub i64 [[GEP1_IDX]], [[J:%.*]]
+; CHECK-NEXT:    ret i64 [[DOTNEG]]
+;
+  %bit = bitcast i8* %foo to i32*
+  %gep1 = getelementptr inbounds i32, i32* %bit, i64 %i
+  %gep2 = getelementptr inbounds i8, i8* %foo, i64 %j
+  %cast1 = ptrtoint i32* %gep1 to i64
+  %cast2 = ptrtoint i8* %gep2 to i64
+  %sub = sub i64 %cast1, %cast2
+  ret i64 %sub
+}
+
+define i16 @test30_as1(i8 addrspace(1)* %foo, i16 %i, i16 %j) {
+; CHECK-LABEL: @test30_as1(
+; CHECK-NEXT:    [[GEP1_IDX:%.*]] = shl nsw i16 [[I:%.*]], 2
+; CHECK-NEXT:    [[DOTNEG:%.*]] = sub i16 [[GEP1_IDX]], [[J:%.*]]
+; CHECK-NEXT:    ret i16 [[DOTNEG]]
+;
+  %bit = bitcast i8 addrspace(1)* %foo to i32 addrspace(1)*
+  %gep1 = getelementptr inbounds i32, i32 addrspace(1)* %bit, i16 %i
+  %gep2 = getelementptr inbounds i8, i8 addrspace(1)* %foo, i16 %j
+  %cast1 = ptrtoint i32 addrspace(1)* %gep1 to i16
+  %cast2 = ptrtoint i8 addrspace(1)* %gep2 to i16
+  %sub = sub i16 %cast1, %cast2
+  ret i16 %sub
+}
+
 define <2 x i64> @test31(<2 x i64> %A) {
 ; CHECK-LABEL: @test31(
 ; CHECK-NEXT:    [[SUB:%.*]] = add <2 x i64> [[A:%.*]], <i64 3, i64 4>
@@ -1075,10 +1236,10 @@ define i64 @test58([100 x [100 x i8]]* %foo, i64 %i, i64 %j) {
 ; "%sub = i64 %i, %j, ret i64 %sub"
 ; gep1 and gep2 have only one use
 ; CHECK-LABEL: @test58(
-; CHECK-NEXT:    [[GEP1_OFFS:%.*]] = add i64 [[I:%.*]], 4200
 ; CHECK-NEXT:    [[GEP2_OFFS:%.*]] = add i64 [[J:%.*]], 4200
-; CHECK-NEXT:    [[GEPDIFF:%.*]] = sub i64 [[GEP1_OFFS]], [[GEP2_OFFS]]
-; CHECK-NEXT:    ret i64 [[GEPDIFF]]
+; CHECK-NEXT:    [[GEP1_OFFS:%.*]] = add i64 [[I:%.*]], 4200
+; CHECK-NEXT:    [[DOTNEG:%.*]] = sub i64 [[GEP1_OFFS]], [[GEP2_OFFS]]
+; CHECK-NEXT:    ret i64 [[DOTNEG]]
 ;
   %gep1 = getelementptr inbounds [100 x [100 x i8]], [100 x [100 x i8]]* %foo, i64 0, i64 42, i64 %i
   %gep2 = getelementptr inbounds [100 x [100 x i8]], [100 x [100 x i8]]* %foo, i64 0, i64 42, i64 %j
@@ -1149,8 +1310,8 @@ define i64 @test61([100 x [100 x i8]]* %foo, i64 %i, i64 %j) {
 
 define i32 @test62(i32 %A) {
 ; CHECK-LABEL: @test62(
-; CHECK-NEXT:    [[B_NEG:%.*]] = mul i32 [[A:%.*]], -2
-; CHECK-NEXT:    [[C:%.*]] = add i32 [[B_NEG]], 2
+; CHECK-NEXT:    [[B:%.*]] = shl i32 [[A:%.*]], 1
+; CHECK-NEXT:    [[C:%.*]] = sub i32 2, [[B]]
 ; CHECK-NEXT:    ret i32 [[C]]
 ;
   %B = sub i32 1, %A
@@ -1160,8 +1321,8 @@ define i32 @test62(i32 %A) {
 
 define <2 x i32> @test62vec(<2 x i32> %A) {
 ; CHECK-LABEL: @test62vec(
-; CHECK-NEXT:    [[B_NEG:%.*]] = mul <2 x i32> [[A:%.*]], <i32 -2, i32 -2>
-; CHECK-NEXT:    [[C:%.*]] = add <2 x i32> [[B_NEG]], <i32 2, i32 2>
+; CHECK-NEXT:    [[B:%.*]] = shl <2 x i32> [[A:%.*]], <i32 1, i32 1>
+; CHECK-NEXT:    [[C:%.*]] = sub <2 x i32> <i32 2, i32 2>, [[B]]
 ; CHECK-NEXT:    ret <2 x i32> [[C]]
 ;
   %B = sub <2 x i32> <i32 1, i32 1>, %A
@@ -1171,8 +1332,8 @@ define <2 x i32> @test62vec(<2 x i32> %A) {
 
 define i32 @test63(i32 %A) {
 ; CHECK-LABEL: @test63(
-; CHECK-NEXT:    [[B_NEG_NEG:%.*]] = shl i32 [[A:%.*]], 1
-; CHECK-NEXT:    ret i32 [[B_NEG_NEG]]
+; CHECK-NEXT:    [[B:%.*]] = shl i32 [[A:%.*]], 1
+; CHECK-NEXT:    ret i32 [[B]]
 ;
   %B = sub i32 1, %A
   %C = shl i32 %B, 1
@@ -1182,8 +1343,8 @@ define i32 @test63(i32 %A) {
 
 define <2 x i32> @test63vec(<2 x i32> %A) {
 ; CHECK-LABEL: @test63vec(
-; CHECK-NEXT:    [[B_NEG_NEG:%.*]] = shl <2 x i32> [[A:%.*]], <i32 1, i32 1>
-; CHECK-NEXT:    ret <2 x i32> [[B_NEG_NEG]]
+; CHECK-NEXT:    [[B:%.*]] = shl <2 x i32> [[A:%.*]], <i32 1, i32 1>
+; CHECK-NEXT:    ret <2 x i32> [[B]]
 ;
   %B = sub <2 x i32> <i32 1, i32 1>, %A
   %C = shl <2 x i32> %B, <i32 1, i32 1>
-- 
2.29.1.341.ge80a0c044ae-goog

